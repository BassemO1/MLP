{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5f92dcb1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f92dcb1",
        "outputId": "aa665298-39da-41a2-a258-6e981a7bcba1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[843   0]\n",
            " [  0 782]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       843\n",
            "           1       1.00      1.00      1.00       782\n",
            "\n",
            "    accuracy                           1.00      1625\n",
            "   macro avg       1.00      1.00      1.00      1625\n",
            "weighted avg       1.00      1.00      1.00      1625\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "\n",
        "# Load sample data\n",
        "df = pd.read_csv(\"mush_num.csv\")\n",
        "y = df['class']\n",
        "x = df.drop('class',axis=1)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create an MLP classifier\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100, ),        # Number of hidden layers and units per layer\n",
        "                    activation='relu',                 # Activation function ('identity', 'logistic', 'tanh', 'relu')\n",
        "                    solver='adam',                     # Solver for weight optimization ('lbfgs', 'sgd', 'adam')\n",
        "                    alpha=0.0001,                      # L2 penalty (regularization term) parameter\n",
        "                    batch_size='auto',                 # Size of minibatches for stochastic optimizers\n",
        "                    learning_rate='constant',          # Learning rate schedule ('constant', 'invscaling', 'adaptive')\n",
        "                    learning_rate_init=0.001,          # The initial learning rate\n",
        "                    power_t=0.5,                       # The exponent for inverse scaling learning rate\n",
        "                    max_iter=200,                      # Maximum number of iterations\n",
        "                    shuffle=True,                      # Whether to shuffle samples in each iteration\n",
        "                    random_state=None,                 # Seed for the random number generator\n",
        "                    tol=0.0001,                        # Tolerance for the optimization\n",
        "                    verbose=False,                     # Whether to print progress messages\n",
        "                    warm_start=False,                  # Reuse the previous solution\n",
        "                    momentum=0.9,                      # Momentum for gradient descent update\n",
        "                    nesterovs_momentum=True,           # Whether to use Nesterov's momentum\n",
        "                    early_stopping=False,              # Terminate training when validation score is not improving\n",
        "                    validation_fraction=0.1,           # Proportion of training data to set aside as validation set\n",
        "                    beta_1=0.9,                        # Exponential decay rate for estimates of first moment vector in adam\n",
        "                    beta_2=0.999,                      # Exponential decay rate for estimates of second moment vector in adam\n",
        "                    epsilon=1e-8,                      # Value for numerical stability in adam\n",
        "                    n_iter_no_change=10,               # Maximum number of epochs without any improvement in the loss\n",
        "                    max_fun=15000)                     # Maximum number of function calls for the solver\n",
        "\n",
        "# Train the MLP classifier\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = mlp.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}